{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score,accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "x_train=train.iloc[:,1:]\n",
    "y_train=train.iloc[:,0]\n",
    "x_test=test.iloc[:,1:]\n",
    "y_test=test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[[-1.48945057 -3.71272545  1.29961779  2.42768985  3.47387325  3.20257516\n",
      "   2.59114753 -0.6944501  -1.17831657 -1.03787861]\n",
      " [ 0.84725766 -2.31637629 -0.15328035  0.66972254  2.99416961  1.25569593\n",
      "  -0.83432013 -0.48455475 -0.88082935  0.43784213]\n",
      " [ 2.20276104 -2.99132273 -2.96705406 -0.34794989  0.39920682 -3.47827415\n",
      "  -3.73578602 -2.65076675 -2.25522418 -0.23303885]\n",
      " [ 4.03678302 -1.31609407 -2.84482309 -1.04735517 -2.2937345  -5.06933189\n",
      "  -3.64192659 -4.65300098 -2.46579722 -1.18928894]\n",
      " [ 2.19747777  1.1729076   0.47990308 -0.91153206 -4.25147538 -1.45603485\n",
      "  -0.34577505 -2.68402742 -1.47293762 -1.09728268]\n",
      " [ 2.56283283  0.27557796  0.00882474 -0.55909109 -2.23248454 -1.298099\n",
      "  -0.25178039 -2.77586333 -1.07403052  0.13572387]\n",
      " [-0.09317273  1.68776601  0.69163702 -0.57976301 -2.27596179 -1.26795647\n",
      "   0.32468526  1.42920469  0.4714198   0.02569688]\n",
      " [-2.83087511  3.81700022  1.01319911  0.07669238 -0.87951862  1.04019107\n",
      "   2.51446136  4.52504287  2.99381495  1.84483718]\n",
      " [-3.01027681  1.87380199  1.34653257  0.0511917   1.79802321  3.36589957\n",
      "   1.69170947  3.97842216  2.41474239  1.19272672]\n",
      " [-4.07571129  2.99468417  1.839748    1.55974817  4.32416323  4.44870701\n",
      "   3.81341469  4.61236863  4.25336587  0.94083439]\n",
      " [-0.34762581 -1.48521942 -0.7143048  -1.3393534  -1.0562613  -0.74337237\n",
      "  -2.12583013 -0.60237504 -0.80620757 -1.02017209]]\n",
      "[ 3  1  2  4  7 11  6  8 11  9  9  2  2  2  4  7  7  6  8  9  9 11  1  2\n",
      "  2  4  7  5  6  8  9  1 11  1  2  2  4  7  5  3  8  9  1 11  1  2  2  3\n",
      "  7  5  6  8  9  1  9  1  2  3  3  7 11  7  8  9  1 10  1  1  4  4  6  5\n",
      "  7  8  9 10 11  1  1  4  4  5  5  5  8  9 10 11  1  1  4  4  6  5  5  8\n",
      "  9  9 11  1  1  4  4  6  5  5  8 10 10 11  1  1  4  4  5  6  5  8 10 10\n",
      " 11  1  1  4  4  5 11 11  8 10 10 11  1  1  3  4  7  6  8  8  8 10 11  1\n",
      "  1  3  4  7 11  8  8 10 10 11  1  1  3  4  7  6  8  8 10 10 11  1  1  3\n",
      "  4  5  6  8  8 10 10 11  1  1  3  4  5  6  7  8 10 10 11  1  1  2 11  5\n",
      "  5  7  8 10 10 11  1  1  3  4  6  4  7 10  9  1 11  1  1  2  4  6  4  7\n",
      " 10  8  1 11  1  1  2  4  4  4  7 10 10  1 11  1  1  2  4 11 11  7  8 10\n",
      "  1 11  1  1  2  4 11  6  7  8 10 10 11  1  1  2  4 11 11  7  8 10 10 11\n",
      "  1  2  4  4  6  6  5  9  8  9 11  1  2  3  4  5  6  5  9  8  9  6  1  2\n",
      "  3  4  6  6  5  9  8  9  6  1  2  4  4  6  6  5  7  8  9 11  1  3  4  4\n",
      "  6  6  6  7 10  9 11  2  3  3  4  6  6  6  8 10  9  7  2  6  6  6  6  3\n",
      "  6  9 11  3  6  1  2  6  6  6  3  6  9 11  3  6  9  2  6  6  6  3  6  9\n",
      " 11  3  6  9  2  6  6  6  3  6  9 11  3  6  9  2  4  6  6  3  6  8  2  3\n",
      "  6  2  2  4  6  6  6  6  5  2  2  6  2  2  3  4  6  6  9 10  9 11  3  2\n",
      "  2  3  4  6  6  5 10  9 11  3  2  1  3  4  6  6  7 10  9 11  6  2  1  3\n",
      "  4  6  6  9 10  9 11  6  2  1  3  4  6  6  9 10  9 11  6  2  1  3  4  6\n",
      "  6  9  9  9 11  2]\n",
      "LDA Accuracy is : 0.44372294372294374\n"
     ]
    }
   ],
   "source": [
    "# LDA (Sigma1=Sigma-1)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "model = lda.fit(x_train, y_train)\n",
    "\n",
    "print(model.priors_) # 11 prior probabilities\n",
    "print(model.coef_)\n",
    "\n",
    "pred=model.predict(x_test)\n",
    "print(pred)\n",
    "\n",
    "#Let us check out the confusion matrix to examine how the model fits well. We well compare the predicted class to the True class\n",
    "#print(confusion_matrix(pred, y_test))\n",
    "#print(classification_report(y_test, pred, digits=3))\n",
    "print(\"LDA Accuracy is :\", accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09090909 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909\n",
      " 0.09090909 0.09090909 0.09090909 0.09090909 0.09090909]\n",
      "[[-3.3595625   0.0629375  -0.2940625   1.20333333  0.38747917  1.22189583\n",
      "   0.096375    0.03710417 -0.62435417 -0.161625  ]\n",
      " [-2.708875    0.49060417 -0.58022917  0.8135      0.2019375   1.06347917\n",
      "  -0.19091667  0.3738125  -0.51595833  0.08060417]\n",
      " [-2.44025     0.774875   -0.79839583  0.80866667  0.04245833  0.56925\n",
      "  -0.2800625   0.20495833 -0.47827083  0.181875  ]\n",
      " [-2.22660417  1.52583333 -0.8744375   0.42214583 -0.3713125   0.24835417\n",
      "  -0.01895833  0.10714583 -0.32627083 -0.05375   ]\n",
      " [-2.7563125   2.27595833 -0.46572917  0.2253125  -1.03679167  0.38979167\n",
      "   0.23641667  0.424625   -0.20070833 -0.28070833]\n",
      " [-2.67354167  1.75877083 -0.4745625   0.3505625  -0.66585417  0.417\n",
      "   0.16233333  0.22925    -0.2075      0.05270833]\n",
      " [-3.24372917  2.46835417 -0.1050625   0.39645833 -0.98029167  0.1623125\n",
      "   0.01958333  0.76229167 -0.03027083 -0.12239583]\n",
      " [-4.05133333  3.23397917 -0.17397917  0.39658333 -1.04602083  0.1951875\n",
      "   0.08666667  0.82077083  0.10445833  0.02122917]\n",
      " [-3.87689583  2.34502083 -0.36683333  0.31704167 -0.3945      0.803375\n",
      "   0.02504167  0.73614583 -0.23183333 -0.14810417]\n",
      " [-4.50614583  2.6885625  -0.28491667  0.4695625  -0.03879167  0.638875\n",
      "   0.13916667  0.3875625  -0.11102083 -0.27335417]\n",
      " [-2.99039583  1.463875   -0.5098125   0.37164583 -0.38039583  0.72504167\n",
      "  -0.08339583  0.50766667 -0.3275     -0.22672917]]\n",
      "[ 1  2  6  4  7  6  7  9  7  7  9  1  2  6  6  7  6  7  9  8  7  9  1  2\n",
      "  2  3  7 11  7  7  9  7  9  1  2  2  3  7 11  7  7  9  7  2  1  2  2  4\n",
      "  7  7  7  7  9  1  9  1  2  2  3  7 11  7  7  9  1 10  1  1  4  5  6  7\n",
      "  7  9  9 10  9  2  1  4  5  6  7  7  9  9  9  9  1  1  4  5  6  7  5  8\n",
      "  9  9 11  1  1  4  5  6  7  5  9  9 10 11  1  1  4  5  6  7  5  9  9 10\n",
      " 11  1  1  1 11  6  6  5  9  9 10 11  1  1  3  4  7  7  7  9  9  9 11  2\n",
      "  1  3  4  7  7  7  9  9 10  9  2  1  3  4  7  7  7  9  9 10  9  9  1  1\n",
      "  4  7  7  9  9  9 10  9  1  1  3  4  7  7  9  9  9 10 11  1  1  3  4  7\n",
      " 11  9  8  9 10 11  1  2  3  4  5  7  7  9  9  2 11  1  3  3  4  7  6  7\n",
      "  9  9  2  9  1  1  3  6  7  7  7  8  9  2  9  1  1  3  6  7  4  7  8  9\n",
      "  2 11  1  1  3  6  5  6  7  8  9 10  9  1  1  3  6  5  7  7  8  9 10 11\n",
      "  1  2  2  6  5  6  5  7  9  9  6  1  2  2  6  5  6  5  7  9  9 11  1  2\n",
      "  2  6  6  6  5  7  7  9 11  1  2  2  6  5  6  5  7  7  9  4  1  2  2  4\n",
      "  5  6  5  7  9  9  4  1  2  2  6  5  6  5  7  9  9  7  1  2  1  6  5  6\n",
      " 11  9  9  9 11  1  2  9  6  5  6 11  9  9  9 11  1  2  1  6  5  6 11  9\n",
      "  9  9 11  1  9  1  6  5  6 11  9  9  9  9  1  2  1  6  5 11 11  9  9  9\n",
      "  9  1  2  1  6  5  6  6  9  9  9  9  2  2  2  6  7  6  7  7  9  9 11  1\n",
      "  2  2  7  7  6  7  7  9  9 11  1  2  3  7  7  6  7  7  9  9 11  1  2  1\n",
      "  4  7  6  7  7  9  9 11  1  1  1  2  5  6  7  7  9  9 11  1  1  2  2  5\n",
      "  6  5  9  9  9  7]\n",
      "QDA Accuracy is : 0.47186147186147187\n"
     ]
    }
   ],
   "source": [
    "# QDA \n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "model_q = qda.fit(x_train, y_train)\n",
    "print(model_q.priors_)\n",
    "print(model_q.means_)\n",
    "\n",
    "pred_q=model_q.predict(x_test)\n",
    "print(pred_q)\n",
    "\n",
    "#print(confusion_matrix(pred_q, y_test))\n",
    "#print(classification_report(y_test, pred_q, digits=3))\n",
    "print(\"QDA Accuracy is :\", accuracy_score(y_test,pred_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Accuracy is : 0.461038961038961\n"
     ]
    }
   ],
   "source": [
    "#NB\n",
    "#Feature Scaling\n",
    "sc = StandardScaler()\n",
    "#X_train = sc.fit_transform(x_train)\n",
    "#X_test = sc.transform(x_test)\n",
    "\n",
    "# Modeling\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "pred_nb  =  classifier.predict(X_test)\n",
    "\n",
    "print(\"NB Accuracy is :\", accuracy_score(y_test,pred_nb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
